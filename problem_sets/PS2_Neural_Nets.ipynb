{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcbegin/DSME6635-S24/blob/main/problem_sets/PS2_Neural_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Problem Set 2 - Implementing Neural Nets\n",
        "\n",
        "### DSME 6635: Artificial Intelligence for Business Research (Spring 2024)\n",
        "\n",
        "### Due at 12:30PM, Tuesday, January 30, 2024\n",
        "\n",
        "Please first copy the CoLab file onto your own Google Drive. Finish the questions below and submit the **CoLab link** of your solutions in [this Google Sheet](https://docs.google.com/spreadsheets/d/1nOE-saTptG73WMCONDB1Z3pt-jHhmDA_1OHpQVHqQ1M/edit#gid=434132169). The total achievable points are 8 for this problem set. Please name you solution as\n",
        "\n",
        "- `Member1LastName_Member1FirstName-Member2LastName_Member2FirstName_PS2.ipynb` (e.g., `Cao_Leo-Zhang_Renyu_PS2.ipynb`)\n",
        "\n",
        "## Pre-requisites\n",
        "\n",
        "For building neural networks, there are two fundamental computational frameworks specificialized towards Deep Learning:\n",
        "1. [TensorFlow](https://www.tensorflow.org/tutorials) implemented by **Google**.\n",
        "2. [PyTorch](https://pytorch.org/tutorials/) implemented by **Facebook**.\n",
        "\n",
        "**You should carefully review the documentations of both frameworks to understand what they do.**"
      ],
      "metadata": {
        "id": "dPRbrMqxS7rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## California Housing Price Prediction\n",
        "\n",
        "In this problem, you are asked to build a three layer multilayer percetron (MLP) to predict the housing price using the Califonira housing data. The following gives you the description of the data:\n",
        "\n",
        "The California Housing dataset, used in this exercise, is a popular dataset for regression tasks in machine learning. It consists of data collected from the 1990 California census and contains information on the median house values for various census blocks in the state of California. The dataset includes 20,640 samples with 8 features, and the goal is to predict the median house value (in units of 100,000 USD) for each block.\n",
        "\n",
        "Features included in the dataset are:\n",
        "\n",
        "1. `MedInc`: Median income in the block\n",
        "2. `HouseAge`: Median age of houses in the block\n",
        "3. `AveRooms`: Average number of rooms per household in the block\n",
        "4. `AveBedrms`: Average number of bedrooms per household in the block\n",
        "5. `Population`: Total population in the block\n",
        "6. `AveOccup`: Average number of occupants per household in the block\n",
        "7. `Latitude`: Latitude of the block\n",
        "8. `Longitude`: Longitude of the block\n",
        "\n",
        "This data set is available in the sklearn.datasets library as part of the `scikit-learn` package. You can find more information about the dataset and its usage in the `scikit-learn` documentations: [California Housing Dataset Description](https://scikit-learn.org/stable/datasets/toy_dataset.html#california-housing-dataset) and\n",
        "[fetch_california_housing function documentation](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_california_housing.html).\n",
        "\n",
        "The original dataset can be found at the following source: Pace, R. Kelley, and Ronald Barry. \"Sparse spatial autoregressions.\" Statistics & Probability Letters 33.3 (1997): 291-297. You may also directly download the data set from Kaggle: https://www.kaggle.com/datasets/camnugent/california-housing-prices"
      ],
      "metadata": {
        "id": "PUTtgESCYPVN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The problem will be divided into several sub-problems and in each of the subproblem  you need to follow the instruction to build the code and there are unit tests at the end of each coding block to test your code for that block.\n",
        "\n",
        "## 1. Loading Packages and Data.\n",
        "\n",
        "You need to use TensorDataset and DataLoader to load both the training and testing data into tensor dataset for PyTorch and DataLoader (so that you can do batch processing). For training data, the shuffle is True and for testing data the shuffle is False. Your default batch size should be 64. See [this tutorial](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) for details.\n",
        "\n"
      ],
      "metadata": {
        "id": "5-lr9BBVY2LV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=666)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Use TensorDataset and DataLoader to process X_train and X_test, and define your returns as train_data, test_data, train_loader and test_loader\n",
        "### BEGIN YOUR CODE HERE\n",
        "train_data = test_data = train_loader = test_loader = None\n",
        "\n",
        "### END YOUR CODE HERE\n"
      ],
      "metadata": {
        "id": "j6ExUDI4S7Ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Assert that the length of train_loader and test_loader are as expected\n",
        "assert len(train_loader) == np.ceil(len(train_data) / train_loader.batch_size), \"Incorrect train_loader length\"\n",
        "assert len(test_loader) == np.ceil(len(test_data) / test_loader.batch_size), \"Incorrect test_loader length\"\n",
        "\n",
        "# Assert that the first batch of training data has the correct size\n",
        "first_batch_features, first_batch_targets = next(iter(train_loader))\n",
        "assert first_batch_features.size(0) == train_loader.batch_size, \"Incorrect batch size for train_loader features\"\n",
        "assert first_batch_targets.size(0) == train_loader.batch_size, \"Incorrect batch size for train_loader targets\"\n"
      ],
      "metadata": {
        "id": "FelSzMTvZnlt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Create a Multilayer Perceptron (MLP) Class.\n",
        "\n",
        "The MLP will have 3 linear layers (input->hidden->hidden->output). Each hidden layer should have hidden_size number of nodes, and use ReLU as the activation function. You are asked to implement both the initialization function (how the neural network structure is built), as well as the foward function (how to calculate the output from the input).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "IDefuscMZnUB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        \"\"\"\n",
        "        This function initializates the neural network\n",
        "        Input:\n",
        "            input_size: the dimension of input data\n",
        "            hidden_size: number of nodes in each hidden layer\n",
        "            output_size: the dimension of output data\n",
        "        Output:\n",
        "            None\n",
        "        \"\"\"\n",
        "        super(MLP, self).__init__()\n",
        "        ### BEGIN YOUR CODE\n",
        "        # Name layers and activation functions as fc1, relu1, fc2, relu2, etc., which will be tested in the next code block\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "\n",
        "    def forward(self, input):\n",
        "        \"\"\"\n",
        "        This function calculates the output from the input\n",
        "        Input:\n",
        "            input: input data\n",
        "        Output:\n",
        "            out: output data derived from the model\n",
        "        \"\"\"\n",
        "        ### BEGIN YOUR CODE\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "h2GAvGJdWu9N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_input_size = 8\n",
        "test_hidden_size = 16\n",
        "test_output_size = 1\n",
        "\n",
        "test_model = MLP(test_input_size, test_hidden_size, test_output_size)\n",
        "\n",
        "assert isinstance(test_model.fc1, nn.Linear), \"First layer should be an instance of nn.Linear\"\n",
        "assert isinstance(test_model.relu1, nn.ReLU), \"ReLU activation function is not properly set\"\n",
        "assert isinstance(test_model.fc2, nn.Linear), \"Second layer should be an instance of nn.Linear\"\n",
        "assert isinstance(test_model.relu2, nn.ReLU), \"ReLU activation function is not properly set\"\n"
      ],
      "metadata": {
        "id": "9n-QRbKFbGIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Set the model's (Hyper)-Parameters and Train the Model.\n",
        "\n",
        "Right now the model has 2 hidden layers with 64 nodes per layer. Train the model for 100 epochs with a learning rate equal to 0.001. You will also use the Adam optimizer for your SGD. In this case, you are going to implement the training loop, where you will make a forward pass, compute the loss and update the gradient (step the optimizer)."
      ],
      "metadata": {
        "id": "-95rd0mabdlQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_size = X_train.shape[1]\n",
        "hidden_size = 64\n",
        "output_size = 1\n",
        "num_epochs = 100\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = MLP(input_size, hidden_size, output_size)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (features, targets) in enumerate(train_loader):\n",
        "        targets = targets.view(-1, 1)\n",
        "\n",
        "        ### BEGIN YOUR CODE\n",
        "        # Forward pass\n",
        "\n",
        "        # Backward pass and optimization\n",
        "\n",
        "        ### END YOUR CODE\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "      print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')"
      ],
      "metadata": {
        "id": "eJoTG0izfKp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Use `sklearn.linear_model` to write a simle linear regression where the features are X and the outcome is Y. You then train the linear regression model on the California Housing Data."
      ],
      "metadata": {
        "id": "7hCs1FE7dQC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "### BEGIN YOUR CODE\n",
        "# Name your linear regression model as linear_reg, and train linear_reg\n",
        "linear_reg = None\n",
        "\n",
        "### END YOUR CODE"
      ],
      "metadata": {
        "id": "FeJfGwK-erPx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert linear_reg.coef_ is not None, \"Model coefficients have not been updated\"\n",
        "assert linear_reg.coef_.shape == (X_train.shape[1],), \"Incorrect number of coefficients\""
      ],
      "metadata": {
        "id": "zT9ur5n9dkOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Compute the Mean Absolute Percentage Error (MAPE) given the predicted and true variables. Then compute the MAPE for both the linear regression model and the MLP model.\n",
        "\n",
        "Note that you should set model to the eval mode so that it is faster. You should also make sure you are not updating the gradients while predicting with torch.no_grad().\n"
      ],
      "metadata": {
        "id": "fdwYDfY5dj8q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function calculates mean absolute percentage error\n",
        "    Input:\n",
        "        y_true: true data\n",
        "        y_pred: prediction data\n",
        "    Output:\n",
        "        mape: mean absolute percentage error * 100\n",
        "    \"\"\"\n",
        "    ### BEGIN YOUR CODE\n",
        "\n",
        "    ### END YOUR CODE\n",
        "\n",
        "\n",
        "\n",
        "### BEGIN YOUR CODE\n",
        "# Get predictions by linear regression model (y_pred_lr)\n",
        "y_pred_lr = None\n",
        "\n",
        "# Get predictions by MLP model (y_pred)\n",
        "y_pred = None\n",
        "\n",
        "### END YOUR CODE\n",
        "\n",
        "\n",
        "mape_mlp = mean_absolute_percentage_error(y_test, y_pred)\n",
        "mape_lr = mean_absolute_percentage_error(y_test, y_pred_lr)\n",
        "\n",
        "print(f'MAPE for MLP Model: {mape_mlp:.2f}%')\n",
        "print(f'MAPE for Linear Regression Model: {mape_lr:.2f}%')"
      ],
      "metadata": {
        "id": "w8AVl8xqiNdT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## End of Problem Set 2."
      ],
      "metadata": {
        "id": "nNsGt6c4r2oL"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3cSYxZer55u"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}