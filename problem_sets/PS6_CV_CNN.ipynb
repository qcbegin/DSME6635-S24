{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcbegin/DSME6635-S24/blob/main/problem_sets/PS6_CV_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FpBsmaEaHJKd",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-a4c41f39205051c2",
          "locked": true,
          "schema_version": 3,
          "solution": false
        }
      },
      "source": [
        "## Problem Set 6 - Convolution Neural Networks\n",
        "\n",
        "### Due at 12:30PM, Tuesday, April 9, 2024\n",
        "\n",
        "Please first copy the CoLab file onto your own Google Drive. Finish the questions below and submit the **CoLab link** of your solutions in [this Google Sheet](https://docs.google.com/spreadsheets/d/1nOE-saTptG73WMCONDB1Z3pt-jHhmDA_1OHpQVHqQ1M/edit#gid=558144135). The total achievable points are 8 for this problem set. Please name you solution as\n",
        "\n",
        "- `Member1LastName_Member1FirstName-Member2LastName_Member2FirstName_PS6.ipynb` (e.g., `Cao_Leo-Zhang_Renyu_PS6.ipynb`)\n",
        "\n",
        "In this problem set, your job is to implement the imfamous image classification algorithms such as AlexNet and ResNet. We will then implement a simple emotion detection algorithm as the subsequent taks.\n",
        "\n",
        "\n",
        "## 1. AlexNet\n",
        "In this exercise, you will use Keras to build a replicate the famous [AlexNet](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf) paper. This paper utilizes a 10-layer network to classify images from [ImageNet](https://image-net.org/) to 1,000 classes.\n",
        "\n",
        "The architecture of Alexnet is:\n",
        "\n",
        "![Alexnet](https://raw.githubusercontent.com/blurred-machine/Data-Science/master/Deep%20Learning%20SOTA/img/alexnet2.png)\n",
        "\n",
        "\n",
        "In the following your will implement the following convolution neural network (CNN) model following the parameter setting in AlexNet.\n",
        "\n",
        "**Note**: Please read the comments carefully to understand what layers to add. There are couple of differences between what we implement here and the original paper:\n",
        "\n",
        "1. In the last layer, you add a softmax with `num_classes` while the original paper will use the `num_classes` in ImageNet.\n",
        "\n",
        "2. We will use the toy training data [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) instead of ImageNet. This means the final outcome is a classification of 10 objects.\n",
        "\n",
        "**Note:** We eventually are training on 10,000 images with 2 classes, so this will take 5 to 10 minutes depending on how much computational resource Google allocates to you. Good luck!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbyEQEkYHJKg",
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b78086c290d4a60c",
          "locked": false,
          "schema_version": 3,
          "solution": true
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from keras.datasets import cifar10\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "\n",
        "\n",
        "class AlexNet(Sequential):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        \"\"\"\n",
        "        This is a class that implements AlexNet. In the following you need to add the\n",
        "        following layers:\n",
        "            1. 1st Conv2D with proper kernel size, channel size, strides, activation, input_shape,\n",
        "            padding = 'valid', kernel_initializer='he_normal' (read the ResNet paper if you are interested)\n",
        "            2. MaxPooling2D with proper strides, pool_size, padding='same'\n",
        "            3. 2nd Conv2D with similar proper parameters, padding='same'\n",
        "            4. MaxPooling2D with similar proper parameters\n",
        "            5. 3rd Conv2D with similar proper parameters\n",
        "            6. 4th Conv2D with similar proper paramteres\n",
        "            7. 5th Conv2D with similar proper parameters\n",
        "            8. MaxPooling2D with similar proper parameters\n",
        "            9. A flatten layer\n",
        "            10. A Dense layer with activation = 'relu' with proper output size\n",
        "            11. A Dense layer with activiation = 'relu' with proper output size\n",
        "            12. A Dense layer with activation = 'relu' with proper output size\n",
        "            13. A Dense layer with softmax activation and output = num_classes\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        ### BEGIN SOLUTION\n",
        "        self.add(Conv2D(filters=96, kernel_size=11, strides=4, input_shape=input_shape, padding='valid', kernel_initializer='he_normal', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
        "        self.add(Conv2D(filters=256, kernel_size=5, strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
        "        self.add(Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(filters=384, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "        self.add(Conv2D(filters=256, kernel_size=3, strides=1, padding='same', activation='relu'))\n",
        "        self.add(MaxPooling2D(pool_size=3, strides=2, padding='same'))\n",
        "        self.add(Flatten())\n",
        "        self.add(Dense(4096, activation='relu'))\n",
        "        self.add(Dense(4096, activation='relu'))\n",
        "        self.add(Dense(1000, activation='relu')) # why there are three FC layers?\n",
        "        self.add(Dense(num_classes, activation='softmax'))\n",
        "        ### END SOLUTION\n",
        "\n",
        "        self.compile(optimizer= tf.keras.optimizers.Adam(0.001),\n",
        "                    loss='categorical_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "\n",
        "def Prepare_CIFAR10():\n",
        "    \"\"\"\n",
        "    This function downloads and prepare the CIFAR10 dataset for training and testing.\n",
        "    Output:\n",
        "        train_generate, val_generator, test_generator: image data generator\n",
        "        x_Train, y_train, x_val, y_val, x_test, y_test: training, validation and testing data\n",
        "    \"\"\"\n",
        "    (x_train, y_train),(x_test, y_test)=cifar10.load_data()\n",
        "    # we only sample 2 classes and 10% of the data\n",
        "    index_1 = np.random.choice(np.concatenate([np.where(y_train == 0)[0], np.where(y_train == 1)[0]]), 5000)\n",
        "    index_2 = np.random.choice(np.concatenate([np.where(y_test == 0)[0], np.where(y_test == 1)[0]]), 5000)\n",
        "    x_train = x_train[index_1]\n",
        "    x_test = x_test[index_2]\n",
        "    y_train = y_train[index_1]\n",
        "    y_test = y_test[index_2]\n",
        "    x_train,x_val,y_train,y_val=train_test_split(x_train,y_train,test_size=.3)\n",
        "    y_train=to_categorical(y_train)\n",
        "    y_val=to_categorical(y_val)\n",
        "    y_test=to_categorical(y_test)\n",
        "    train_generator = ImageDataGenerator(rescale=1./255, rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "    val_generator = ImageDataGenerator(rescale=1./255, rotation_range=2, horizontal_flip=True,zoom_range=.1)\n",
        "    test_generator = ImageDataGenerator(rescale=1./255, rotation_range=2, horizontal_flip= True,zoom_range=.1)\n",
        "    train_generator.fit(x_train)\n",
        "    val_generator.fit(x_val)\n",
        "    test_generator.fit(x_test)\n",
        "    return train_generator, val_generator, test_generator, x_train, y_train, x_val, y_val, x_test, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nQZHyPAHJKj",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-edb04d32c9a4905f",
          "locked": true,
          "points": 50,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ReduceLROnPlateau\n",
        "lrr = ReduceLROnPlateau(monitor='val_acc', factor=.01, patience=3, min_lr=1e-5) # Reduce the learning rate when the validation accuracy stops improving.\n",
        "\n",
        "train_generator, val_generator, test_generator, x_train, y_train, x_val, y_val, x_test, y_test = Prepare_CIFAR10()\n",
        "model = AlexNet((32, 32, 3), 2)\n",
        "assert list(model.layers[0].weights[0].shape) == [11, 11, 3, 96]\n",
        "assert list(model.layers[0].weights[1].shape) == [96]\n",
        "assert list(model.layers[2].weights[0].shape) == [5, 5, 96, 256]\n",
        "assert len(model.layers) == 13\n",
        "### BEGIN HIDDEN TESTS\n",
        "assert list(model.layers[4].weights[0].shape) == [3, 3, 256, 384]\n",
        "assert list(model.layers[12].weights[0].shape) == [1000, 2]\n",
        "### END HIDDEN TESTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JtmSxUSZHJKj",
        "nbgrader": {
          "grade": true,
          "grade_id": "cell-202c311b20e121bd",
          "locked": true,
          "points": 50,
          "schema_version": 3,
          "solution": false,
          "task": false
        }
      },
      "outputs": [],
      "source": [
        "model.fit(train_generator.flow(x_train, y_train, batch_size=32),\n",
        "          epochs=10, steps_per_epoch=100,\n",
        "          validation_data=val_generator.flow(x_val, y_val, batch_size=32),\n",
        "          validation_steps = x_val.shape[0], verbose=1)\n",
        "assert np.sum(model.predict(np.array([x_test[1]])) == y_test[1]) == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JT41PljZf4ws"
      },
      "source": [
        "## 2. ResNet-50 Training\n",
        "\n",
        "In this section, we are going to apply ResNet-50 to a gender classification on 500 [Cryptopunk](https://www.larvalabs.com/cryptopunks) images. We are going to rely on the [ResNet-50 implementation from Keras](https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet50/ResNet50). In particular, we will use weights trained from imagenet data and average pooling for our ResNet50. All images are in [**the course GitHub site**](https://github.com/rphilipzhang/AI-PhD-S24/tree/179826a3f4ae099ace55735a662eed5ad20f6a7f/Data/PS6) and should be uploaded to this notebook. Labels of the images are stored in `gender_label.csv**`, which is also in [**the course GitHub site**](https://github.com/rphilipzhang/AI-PhD-S24/tree/179826a3f4ae099ace55735a662eed5ad20f6a7f/Data/PS6) (again it should be uploaded to this notebook). The application will be decomposed into two functions which will be tested individually.\n",
        "\n",
        "1. `load_image_label()`: This function will load images and labels and return four variables: `X_train`, `X_test`, `y_train`, `y_test`. You will need to load images and labels, convert images to array-like data frame, center pixel value of images to 0 by dividing 255, and split image data and label data into training dataset and testing dataset by 80% : 20%.\n",
        "\n",
        "2. `ResNet50_Adoption(X_train,X_test,y_train,y_test)`: This function does the following:\n",
        "\n",
        " - Build a CNN model by adopting existing `ResNet50` model and keep its original weights.\n",
        " - Train the model with `X_train` and `y_train`.\n",
        " - Test the model with `X_test` and `y_test`.\n",
        " - Return trained model and model accuracy on gender classfication on testing dataset.\n",
        "\n",
        "  2.1. **The model starts with `ResNet50`, then a `BatchNormalization` layer, then a `Dense` layer with 16 neurons and `ReLu` activation function, then another `BatchNormalization` layer, and at last a `Softmax` layer to predict the gender.**\n",
        "\n",
        "  2.2. The model will be trained on the training data and evaluated on the testing data. The model will be trained with `binary_crossentropy` as the loss and `accuracy` as the metric. We will train for 80 epochs with `batch_size = 16` and `validation_split` to be 0.1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fcOb63H_hgLb"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import image\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "import os\n",
        "from PIL import Image\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "Oy4vfem5hufo"
      },
      "outputs": [],
      "source": [
        "def load_image_label():\n",
        "\n",
        "  X_train = X_test = y_train = y_test = None\n",
        "\n",
        "  ### BEGIN YOUR SOLUTION\n",
        "  img_names = [name for name in uploaded.keys() if name.endswith('.png')]\n",
        "  labels = pd.read_csv('gender_label.csv')['type']\n",
        "  \n",
        "  X = np.zeros((len(img_names), 32, 32, 3))\n",
        "  y = []\n",
        "\n",
        "  for index, img_name in enumerate(img_names):\n",
        "    id = int(img_name.split('.')[0])\n",
        "    img = Image.open(img_name)\n",
        "    img = img.resize((32, 32))\n",
        "    img = np.array(img) \n",
        "    X[index] = img\n",
        "    y.append(labels[id])\n",
        "\n",
        "  X = np.array(X) / 255 # normalize the image\n",
        "  y = to_categorical([0 if i == \"Male\" else 1 for i in y])\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X[:500], y[:500], test_size=0.2)\n",
        "  \n",
        "  ### END YOUR SOLUTION\n",
        "\n",
        "  return X_train, X_test, y_train, y_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQSS_dEziyn_"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "X_train, X_test, y_train, y_test= load_image_label()\n",
        "\n",
        "assert X_train.shape == (400, 32, 32, 3)\n",
        "assert X_test.shape == (100, 32, 32, 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z_RztWc4i3aH"
      },
      "outputs": [],
      "source": [
        "def ResNet50_Adoption(X_train,X_test,y_train,y_test):\n",
        "  \"\"\"\n",
        "  The function will take training and testing data and output the trained model\n",
        "  based on the training data as well as the score representing the accuracy of\n",
        "  the model evaluated on the testing data.\n",
        "  \"\"\"\n",
        "\n",
        "  model = Sequential()\n",
        "  score = 0\n",
        "\n",
        "  ### BEGIN YOUR SOLUTION\n",
        "  model.add(ResNet50(include_top=False, weights='imagenet', input_shape=(32, 32, 3), pooling='avg'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "  \n",
        "  model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "  model.fit(X_train, y_train, epochs=80, batch_size=16, validation_split=0.1)\n",
        "  score = model.evaluate(X_test, y_test)\n",
        "  \n",
        "  ### END YOUR SOLUTION\n",
        "\n",
        "  return model, score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cngEi_7wi_XZ"
      },
      "outputs": [],
      "source": [
        "os.environ['PYTHONHASHSEED']=str(1)\n",
        "tf.random.set_seed(1)\n",
        "\n",
        "model,score = ResNet50_Adoption(X_train,X_test,y_train,y_test)\n",
        "\n",
        "assert score[1] > 0.9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kYRB8yZ3pXb2"
      },
      "outputs": [],
      "source": [
        "#show some examples\n",
        "labels = ['male','female']\n",
        "y_hat = model.predict(X_test)\n",
        "figure = plt.figure(figsize=(20,8))\n",
        "for i, index in enumerate(np.random.choice(X_test.shape[0],size=15,replace=False)):\n",
        "    ax = figure.add_subplot(3,5,i+1,xticks=[],yticks=[])\n",
        "    img = np.squeeze(X_test[index])\n",
        "    img *= 255\n",
        "    ax.imshow(img.astype('uint8'))\n",
        "    predict_index = np.argmax(y_hat[index])\n",
        "    true_index = np.argmax(y_test[index])\n",
        "    ax.set_title(\"{} ({})\".format(labels[predict_index],labels[true_index]),color=(\"green\" if predict_index == true_index else \"red\"))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oW8jSq04NZH7"
      },
      "source": [
        "# End of Problem Set 6."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GE96jwF7r2ym"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "toc": {
      "colors": {
        "hover_highlight": "#DAA520",
        "navigate_num": "#000000",
        "navigate_text": "#333333",
        "running_highlight": "#FF0000",
        "selected_highlight": "#FFD700",
        "sidebar_border": "#EEEEEE",
        "wrapper_background": "#FFFFFF"
      },
      "moveMenuLeft": true,
      "nav_menu": {
        "height": "30px",
        "width": "252px"
      },
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "threshold": 4,
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": "block",
      "toc_window_display": false,
      "widenNotebook": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
