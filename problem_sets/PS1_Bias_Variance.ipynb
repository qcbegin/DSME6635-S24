{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qcbegin/DSME6635-S24/blob/main/problem_sets/PS1_Bias_Variance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2e894704",
      "metadata": {
        "id": "2e894704"
      },
      "source": [
        "# Problem Set 1 - Bias-Variance Trade-off\n",
        "\n",
        "### DSME 6635: Artificial Intelligence for Business Research (Spring 2024)\n",
        "\n",
        "### Due at 12:30PM, Tuesday, January 16, 2024\n",
        "\n",
        "Please first copy the CoLab file onto your own Google Drive. Finish the questions below and submit the **CoLab link** of your solutions in [this Google Sheet](https://docs.google.com/spreadsheets/d/1nOE-saTptG73WMCONDB1Z3pt-jHhmDA_1OHpQVHqQ1M/edit#gid=517617149). The total achievable points are 8 for this problem set. Please name you solution as\n",
        "\n",
        "- `Member1LastName_Member1FirstName-Member2LastName_Member2FirstName_PS1.ipynb` (e.g., `Cao_Leo-Zhang_Renyu_PS1.ipynb`)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The bias-variance trade-off is the most important trade-off in supervised learning. This exercise is designed to help you better understand this trade-off. You will work with the Boston Housing data set which we used in class demonstrations. You will be reading in this data set, split the data set into training and testing samples, and then fit polynomial functions for this data set."
      ],
      "metadata": {
        "id": "f9rE07njR64Z"
      },
      "id": "f9rE07njR64Z"
    },
    {
      "cell_type": "markdown",
      "id": "6d6d534e",
      "metadata": {
        "id": "6d6d534e"
      },
      "source": [
        "## 1. Read Data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c43e37c",
      "metadata": {
        "id": "8c43e37c"
      },
      "source": [
        "Create a function `read_data(degree=1)` which will read in the data and return four variables, X1, Y1 and X2, Y2. You need to first split the data into two datasets: the top 80% (you need to round up the splitting number for the top 80%. i.e., if there are 11 rows in the data, the top 80% should be the first 9 rows) will be the training data and the remaining 20% will be testing data. X1 and Y1 represent the features (`indus`, `rm`, and `lstat`) and labels (`medv`). Therefore, Y1 will be a vector and X1 is a matrix whose width depends on degree. If degree is 1, X1 has width 4 (3 features + the constant). Last, X2 and Y2 are polynomials of the features and `medv` for the testing data. In order to generate the polynomial of features, you can use [the function from sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary packages.\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import PolynomialFeatures as PolyF\n",
        "from sklearn.linear_model import LinearRegression as LinReg\n",
        "\n",
        "# Load the data from our course GitHub repo.\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/rphilipzhang/AI-PhD-S24/main/Data/BostonHousing.csv\"\n",
        "df_BH = pd.read_csv(url)\n",
        "\n",
        "def read_data(degree=1,df=df_BH):\n",
        "    \"\"\"\n",
        "    This function will read in the data frame and return training and\n",
        "    testing samples.\n",
        "    Input:\n",
        "        degree: the highest degree of polynomials.\n",
        "    Output:\n",
        "        X1: training features\n",
        "        Y1: training labels\n",
        "        X2: testing features\n",
        "        Y2: testing labels\n",
        "        (Note: the column sequence of X1 and X2 should follow the same sequence as the column sequence in the original dataframe)\n",
        "    \"\"\"\n",
        "    X1 = Y1 = X2 = Y2 = np.array([])\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return X1, Y1, X2, Y2"
      ],
      "metadata": {
        "id": "YfR7uCsCbjHv"
      },
      "id": "YfR7uCsCbjHv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the read_data function with degree=1.\n",
        "\n",
        "X1, Y1, X2, Y2 = read_data(degree=1,df=df_BH)\n",
        "assert X1.shape == (405, 4)\n",
        "assert X2.shape == (101, 4)\n",
        "assert Y1.size == 405\n",
        "assert Y2.size == 101"
      ],
      "metadata": {
        "id": "slDfqIC2cPSH"
      },
      "id": "slDfqIC2cPSH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the read_data function with degree=2.\n",
        "\n",
        "X1, Y1, X2, Y2 = read_data(degree=2,df=df_BH)\n",
        "assert X1.shape == (405, 10)\n",
        "assert X2.shape == (101, 10)\n",
        "assert Y1.size == 405\n",
        "assert Y2.size == 101"
      ],
      "metadata": {
        "id": "jpVqpr3ZddlC"
      },
      "id": "jpVqpr3ZddlC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "a79b4805",
      "metadata": {
        "id": "a79b4805"
      },
      "source": [
        "## 2. Evaluate the Training and Testing Errors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0a81c751",
      "metadata": {
        "id": "0a81c751"
      },
      "source": [
        "Create a function `generate_error(X1, Y1, X2, Y2)` which trains a linear regression model of Y1 on X1. It will then output the `insample_mean_squared_error` and `outofsample_mean_squared_error`. `insample_mean_squared_error` is based on `Y1`, and `outofsample_mean_squared_error` is based on `Y2`. You can use the sklearn function to run [linear regression predictors](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_mse(X1, Y1, X2, Y2):\n",
        "    \"\"\"\n",
        "    This function takes in the training and testing features and labels,\n",
        "    it will return the in_sample and out_of_sample errors of linear regression.\n",
        "    Input:\n",
        "        X1, Y1: features and labels for training samples\n",
        "        X2, Y2: features and labels for testing samples\n",
        "    Ouput:\n",
        "        in_sample_mse, out_of_sample_mse: in-sample and out-of-sample mean suqared error of the model\n",
        "    \"\"\"\n",
        "    in_sample_mse = out_of_sample_mse = 0\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return in_sample_mse, out_of_sample_mse"
      ],
      "metadata": {
        "id": "WLm_-6MwibEU"
      },
      "id": "WLm_-6MwibEU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the read_data function with degree=1.\n",
        "\n",
        "X1, Y1, X2, Y2 = read_data(degree=1,df=df_BH)\n",
        "in_sample_mse, out_of_sample_mse = generate_mse(X1, Y1, X2, Y2)\n",
        "assert np.isclose(in_sample_mse, 30.04818814902604)\n",
        "assert np.isclose(out_of_sample_mse, 39.459195874785145)"
      ],
      "metadata": {
        "id": "zmdxrtYrj_fK"
      },
      "id": "zmdxrtYrj_fK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the read_data function with degree=2.\n",
        "\n",
        "X1, Y1, X2, Y2 = read_data(degree=2,df=df_BH)\n",
        "in_sample_mse, out_of_sample_mse = generate_mse(X1, Y1, X2, Y2)\n",
        "assert np.isclose(in_sample_mse, 16.18744994075758)\n",
        "assert np.isclose(out_of_sample_mse, 18.541655356264993)"
      ],
      "metadata": {
        "id": "zHTfzPQbkJn4"
      },
      "id": "zHTfzPQbkJn4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "d9900735",
      "metadata": {
        "id": "d9900735"
      },
      "source": [
        "## 3. Generate a Vector of Errors"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b425c7f",
      "metadata": {
        "id": "4b425c7f"
      },
      "source": [
        "Create a function `generate_error_vectors(degrees=[])` which generates two lists representing the insample_mse and outofsample_mse for each polynomial degree defined in the input. For example, if the input is [1,3,5,8], then the function will return two lists of length 4 representing the in-sample and out-of-sample mean squared error corresponding to that the polynomial degree is 1, 3, 5 and 8."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_error_vectors(degrees):\n",
        "    \"\"\"\n",
        "    This function takes a list of hyperparameteres of degrees and returns\n",
        "    the in-sample and out-of-sample errors of each hyperparameter.\n",
        "    Input:\n",
        "        degress: a list of higest degrees of functions to fit\n",
        "    Output:\n",
        "        in_sample_mses, out_of_sample_mses: the in-sample and out-of-sample\n",
        "        mean squared error corresponding to each hyper-parameter in the input\n",
        "        list.\n",
        "    \"\"\"\n",
        "\n",
        "    in_sample_mses = []\n",
        "    out_of_sample_mses = []\n",
        "\n",
        "    ### BEGIN SOLUTION\n",
        "    ### END SOLUTION\n",
        "\n",
        "    return in_sample_mses, out_of_sample_mses"
      ],
      "metadata": {
        "id": "D8QDSrjFlovS"
      },
      "id": "D8QDSrjFlovS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unit tests for the function generate_error_vectors()\n",
        "\n",
        "in_sample_mses, out_of_sample_mses = generate_error_vectors(list(range(1, 6)))\n",
        "assert len(in_sample_mses) == 5\n",
        "assert len(out_of_sample_mses) == 5\n",
        "assert np.isclose(in_sample_mses[3], 12.163525946822281)\n",
        "assert np.isclose(out_of_sample_mses[3], 20.638652953787005)"
      ],
      "metadata": {
        "id": "wfLqW2JamvKf"
      },
      "id": "wfLqW2JamvKf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the optimal degree? Please discuss how your generated error vectors relate to the bias-variance tradeoff."
      ],
      "metadata": {
        "id": "8RfYB3y9nReo"
      },
      "id": "8RfYB3y9nReo"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Provide your answers here."
      ],
      "metadata": {
        "id": "gKA8b2wvn92x"
      },
      "id": "gKA8b2wvn92x"
    },
    {
      "cell_type": "markdown",
      "id": "f27793c8",
      "metadata": {
        "id": "f27793c8"
      },
      "source": [
        "## End of Problem Set 1."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WKMMgevmniJJ"
      },
      "id": "WKMMgevmniJJ",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}